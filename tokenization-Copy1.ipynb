{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa2a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ce7b2",
   "metadata": {},
   "source": [
    "#### Steps NLP\n",
    "\n",
    "1.Tokenization\n",
    "\n",
    "2.Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f789fb31",
   "metadata": {},
   "source": [
    "## 1. Tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#. Tokenize this document with SpaCy:\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09841b84",
   "metadata": {},
   "source": [
    "### Reading text/tokens with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading text with spacy\n",
    "docx = nlp(text)\n",
    "docx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f02f9f3",
   "metadata": {},
   "source": [
    "### Toknize text with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4d15c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number sentecnes in text\n",
    "for num, sentence in enumerate(docx.sents):\n",
    "    print(f'{num}: {sentence}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of tokens in text\n",
    "for num, token in enumerate(docx):\n",
    "    print(f'{num}: {token.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4cb96d",
   "metadata": {},
   "source": [
    "## 2. Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e2a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding with spacy\n",
    "sentence = \"I love learning\"\n",
    "\n",
    "# Assigning vectors to words\n",
    "doc = nlp(sentence)\n",
    "\n",
    "#Checking vector for 2nd word in sentence: 'Love'\n",
    "doc[1].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a0f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean vector for whole sentence (used in sentence classification)\n",
    "doc.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f9725f",
   "metadata": {},
   "source": [
    "### Embedding using Flair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b01919",
   "metadata": {},
   "source": [
    "- This embeds the sentence with GloVe embeddings, then prints out the embedding of each word. Each word embedding in this case has the shape [100], i.e. a 100 dimensional vector.\n",
    "\n",
    "- Then we use torch.cat to concatenate all embeddings of all words in the sentence into a tensor of shape [3, 100] (3 words, each 100 dimensions).\n",
    "\n",
    "- If you want to have a batch of more than one sentence, you need to use torch.cat again to concatenate the tensors of each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd42097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenaize setence with Flair\n",
    "s= Sentence(\"I love learning\")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e9e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word embeddings\n",
    "embeddings = WordEmbeddings('glove')\n",
    "\n",
    "# embed sentences 's'\n",
    "embeddings.embed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through each token in sentence\n",
    "for token in s:\n",
    "\n",
    "# print embedding of this Token\n",
    "    print(token.embedding)\n",
    "\n",
    "\n",
    "# print shape of embedding of this Token   \n",
    "    print(token.embedding.shape)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cad318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print shape of embedding of this Token\n",
    "for token in s:\n",
    "    print(token.embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a2fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make one tensor(multi-dimension array) of all word embeddings of a sentence 's'\n",
    "sentence_tensor = torch.cat([token.embedding.unsqueeze(0) for token in s], dim=0)\n",
    "\n",
    "'''\n",
    "A tensor is a multidimension array of a \n",
    "tokenaized(broken down sentence in individual words) sentence\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print tensor(multi-dimension array) shape \n",
    "print(sentence_tensor.shape) \n",
    "'''\n",
    "output is 3 rows representing the 3 words in the sentence\n",
    "&\n",
    "Each word has 100 columns (which is the size of @column)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89310d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
