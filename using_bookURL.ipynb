{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0066142",
   "metadata": {},
   "source": [
    "# Using book URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ca535",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb365731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "BART_PATH = 'facebook/bart-large-cnn'\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url to summarize\n",
    "URL = \"url of book\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c2044d",
   "metadata": {},
   "source": [
    "## 2. Function to get URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cff1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(URL):\n",
    "    r = requests.get(URL)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    results = soup.find_all(['body'])\n",
    "    text = [result.text for result in results]\n",
    "    article = ' '.join(text)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc16023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating variable of text to be summarized with url\n",
    "my_book = get_url(URL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f409e7",
   "metadata": {},
   "source": [
    "## 3. Function to chunk text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525133ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nest_sentences(document):\n",
    "    nested = []\n",
    "    sent = []\n",
    "    length = 0\n",
    "    for sentence in nltk.sent_tokenize(document):\n",
    "        length += len(sentence)\n",
    "        if length < 500:\n",
    "            sent.append(sentence)\n",
    "        else:\n",
    "            nested.append(sent)\n",
    "            sent = []\n",
    "            length = 0\n",
    "\n",
    "    if sent:\n",
    "        nested.append(sent)\n",
    "\n",
    "    return nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e411e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating variable for chunked text\n",
    "nested = nest_sentences(my_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b8593f",
   "metadata": {},
   "source": [
    "## 4. Function to generate summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e00f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(nested_sentences):\n",
    "    \n",
    "    #Invoking models for summariation & tokenization\n",
    "    bart_model = BartForConditionalGeneration.from_pretrained(BART_PATH, output_past=True)\n",
    "    bart_tokenizer = BartTokenizer.from_pretrained(BART_PATH, output_past=True)\n",
    "     \n",
    "    # using cuda for summarization\n",
    "    device = 'cuda'\n",
    "    summaries = []\n",
    "    for nested in nested_sentences:\n",
    "        input_tokenized = bart_tokenizer.encode(' '.join(nested), truncation=True, return_tensors='pt')\n",
    "        input_tokenized = input_tokenized.to(device)\n",
    "        summary_ids = bart_model.to('cuda').generate(input_tokenized,\n",
    "                                        length_penalty=3.0,\n",
    "                                        min_length=30,\n",
    "                                        max_length=100)\n",
    "        output = [bart_tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "        summaries.append(output)\n",
    "    summaries = [sentence for sublist in summaries for sentence in sublist]\n",
    "    \n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b245f16",
   "metadata": {},
   "source": [
    "## 5. Function to generate 2-level summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd363553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalSummary(chunked_text):\n",
    "    summary_one = generate_summary(chunked_text)\n",
    "    nested_summ = nest_sentences(' '.join(summary_one))\n",
    "    final_summary = generate_summary(nested_summ)\n",
    "    print(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cffaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling summary function on chunked text\n",
    "finalSummary(nested)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
