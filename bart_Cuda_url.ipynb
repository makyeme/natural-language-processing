{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0066142",
   "metadata": {},
   "source": [
    "# Using huggingface's transformers\n",
    "(containg pretrained models fot auto text sumerization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c27eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "BART_PATH = 'facebook/bart-large-cnn'\n",
    "from rouge import Rouge\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#url to summarize\n",
    "url = \"https://www.nytimes.com/2021/04/30/technology/robot-surgery-surgeon.html\"\n",
    "\n",
    "\n",
    "#function to get url\n",
    "def get_url(URL):\n",
    "    r = requests.get(URL)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    results = soup.find_all(['body'])\n",
    "    text = [result.text for result in results]\n",
    "    article = ' '.join(text)\n",
    "    return article\n",
    "\n",
    "\n",
    "#creating variable of text to be summarized with url\n",
    "my_book = get_url(url)\n",
    "\n",
    "\n",
    "\n",
    "#function to chunk text\n",
    "def nest_sentences(document):\n",
    "    nested = []\n",
    "    sent = []\n",
    "    length = 0\n",
    "    for sentence in nltk.sent_tokenize(document):\n",
    "        length += len(sentence)\n",
    "        if length < 500:\n",
    "            sent.append(sentence)\n",
    "        else:\n",
    "            nested.append(sent)\n",
    "            sent = []\n",
    "            length = 0\n",
    "\n",
    "    if sent:\n",
    "        nested.append(sent)\n",
    "\n",
    "    return nested\n",
    "#Creating variable for chunked text\n",
    "nested = nest_sentences(my_book)\n",
    "\n",
    "#function to generate summary\n",
    "\n",
    "def generate_summary(nested_sentences):\n",
    "    \n",
    "    #model for summariation & tokenization\n",
    "    bart_model = BartForConditionalGeneration.from_pretrained(BART_PATH, output_past=True)\n",
    "    bart_tokenizer = BartTokenizer.from_pretrained(BART_PATH, output_past=True)\n",
    "     \n",
    "    # using cuda for summarization\n",
    "    device = 'cuda'\n",
    "    summaries = []\n",
    "    for nested in nested_sentences:\n",
    "        input_tokenized = bart_tokenizer.encode(' '.join(nested), truncation=True, return_tensors='pt')\n",
    "        input_tokenized = input_tokenized.to(device)\n",
    "        summary_ids = bart_model.to('cuda').generate(input_tokenized,\n",
    "                                        length_penalty=3.0,\n",
    "                                        min_length=30,\n",
    "                                        max_length=100)\n",
    "        output = [bart_tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "        summaries.append(output)\n",
    "    summaries = [sentence for sublist in summaries for sentence in sublist]\n",
    "    return summaries\n",
    "\n",
    "# generating 2 level summary\n",
    "\n",
    "def finalSummary(chunked_text):\n",
    "    summary_one = generate_summary(chunked_text)\n",
    "    nested_summ = nest_sentences(' '.join(summary_one))\n",
    "    final_summary = generate_summary(nested_summ)\n",
    "    print(final_summary)\n",
    "\n",
    "#Calling summary function on chunked text\n",
    "finalSummary(nested)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74109b",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd3fa71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\makye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\makye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "BART_PATH = 'facebook/bart-large-cnn'\n",
    "from rouge import Rouge\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04c84d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(URL):\n",
    "    r = requests.get(URL)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    results = soup.find_all(['h1', 'p'])\n",
    "    text = [result.text for result in results]\n",
    "    article = ' '.join(text)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5a4734f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Advertisement Supported by The Robot Surgeon Will See You Now Real scalpels, artificial intelligence — what could go wrong? By Cade Metz Sitting on a stool several feet from a long-armed robot, Dr. Danyal Fer wrapped his fingers around two metal handles near his chest. As he moved the handles — up and down, left and right — the robot mimicked each small motion with its own two arms. Then, when he pinched his thumb and forefinger together, one of the robot’s tiny claws did much the same. This is how surgeons like Dr. Fer have long used robots when operating on patients. They can remove a prostate from a patient while sitting at a computer console across the room. But after this brief demonstration, Dr. Fer and his fellow researchers at the University of California, Berkeley, showed how they hope to advance the state of the art. Dr. Fer let go of the handles, and a new kind of computer software took over. As he and the other researchers looked on, the robot started to move entirely on its own. With one claw, the machine lifted a tiny plastic ring from an equally tiny peg on the table, passed the ring from one claw to the other, moved it across the table and gingerly hooked it onto a new peg. Then the robot did the same with several more rings, completing the task as quickly as it had when guided by Dr. Fer. The training exercise was originally designed for humans; moving the rings from peg to peg is how surgeons learn to operate robots like the one in Berkeley. Now, an automated robot performing the test can match or even exceed a human in dexterity, precision and speed, according to a new research paper from the Berkeley team. The project is a part of a much wider effort to bring artificial intelligence into the operating room. Using many of the same technologies that underpin self-driving cars, autonomous drones and warehouse robots, researchers are working to automate surgical robots too. These methods are still a long way from everyday use, but progress is accelerating. “It is an exciting time,” said Russell Taylor, a professor at Johns Hopkins University and former IBM researcher known in the academic world as the father of robotic surgery. “It is where I hoped we would be 20 years ago.” The aim is not to remove surgeons from the operating room but to ease their load and perhaps even raise success rates — where there is room for improvement — by automating particular phases of surgery. Robots can already exceed human accuracy on some surgical tasks, like placing a pin into a bone (a particularly risky task during knee and hip replacements). The hope is that automated robots can bring greater accuracy to other tasks, like incisions or suturing, and reduce the risks that come with overworked surgeons. During a recent phone call, Greg Hager, a computer scientist at Johns Hopkins, said that surgical automation would progress much like the Autopilot software that was guiding his Tesla down the New Jersey Turnpike as he spoke. The car was driving on its own, he said, but his wife still had her hands on the wheel, should anything go wrong. And she would take over when it was time to exit the highway. “We can’t automate the whole process, at least not without human oversight,” he said. “But we can start to build automation tools that make the life of a surgeon a little bit easier.” Five years ago, researchers with the Children’s National Health System in Washington, D.C., designed a robot that could automatically suture the intestines of a pig during surgery. It was a notable step toward the kind of future envisioned by Dr. Hager. But it came with an asterisk: The researchers had implanted tiny markers in the pig’s intestines that emitted a near-infrared light and helped guide the robot’s movements. The method is far from practical, as the markers are not easily implanted or removed. But in recent years, artificial intelligence researchers have significantly improved the power of computer vision, which could allow robots to perform surgical tasks on their own, without such markers. The change is driven by what are called neural networks, mathematical systems that can learn skills by analyzing vast amounts of data. By analyzing thousands of cat photos, for instance, a neural network can learn to recognize a cat. In much the same way, a neural network can learn from images captured by surgical robots. Surgical robots are equipped with cameras that record three-dimensional video of each operation. The video streams into a viewfinder that surgeons peer into while guiding the operation, watching from the robot’s point of view. But afterward, these images also provide a detailed road map showing how surgeries are performed. They can help new surgeons understand how to use these robots, and they can help train robots to handle tasks on their own. By analyzing images that show how a surgeon guides the robot, a neural network can learn the same skills. This is how the Berkeley researchers have been working to automate their robot, which is based on the da Vinci Surgical System, a two-armed machine that helps surgeons perform more than a million procedures a year. Dr. Fer and his colleagues collect images of the robot moving the plastic rings while under human control. Then their system learns from these images, pinpointing the best ways of grabbing the rings, passing them between claws and moving them to new pegs. But this process came with its own asterisk. When the system told the robot where to move, the robot often missed the spot by millimeters. Over months and years of use, the many metal cables inside the robot’s twin arms have stretched and bent in small ways, so its movements were not as precise as they needed to be. Human operators could compensate for this shift, unconsciously. But the automated system could not. This is often the problem with automated technology: It struggles to deal with change and uncertainty. Autonomous vehicles are still far from widespread use because they aren’t yet nimble enough to handle all the chaos of the everyday world. The Berkeley team decided to build a new neural network that analyzed the robot’s mistakes and learned how much precision it was losing with each passing day. “It learns how the robot’s joints evolve over time,” said Brijen Thananjeyan, a doctoral student on the team. Once the automated system could account for this change, the robot could grab and move the plastics rings, matching the performance of human operators. Other labs are trying different approaches. Axel Krieger, a Johns Hopkins researcher who was part of the pig-suturing project in 2016, is working to automate a new kind of robotic arm, one with fewer moving parts and that behaves more consistently than the kind of robot used by the Berkeley team. Researchers at the Worcester Polytechnic Institute are developing ways for machines to carefully guide surgeons’ hands as they perform particular tasks, like inserting a needle for a cancer biopsy or burning into the brain to remove a tumor. “It is like a car where the lane-following is autonomous but you still control the gas and the brake,” said Greg Fischer, one of the Worcester researchers. Many obstacles lie ahead, scientists note. Moving plastic pegs is one thing; cutting, moving and suturing flesh is another. “What happens when the camera angle changes?” said Ann Majewicz Fey, an associate professor at the University of Texas, Austin. “What happens when smoke gets in the way?” For the foreseeable future, automation will be something that works alongside surgeons rather than replaces them. But even that could have profound effects, Dr. Fer said. For instance, doctors could perform surgery across distances far greater than the width of the operating room — from miles or more away, perhaps, helping wounded soldiers on distant battlefields. The signal lag is too great to make that possible currently. But if a robot could handle at least some of the tasks on its own, long-distance surgery could become viable, Dr. Fer said: “You could send a high-level plan and then the robot could carry it out.” The same technology would be essential to remote surgery across even longer distances. “When we start operating on people on the moon,” he said, “surgeons will need entirely new tools.” Advertisement'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_book = get_url(\"https://www.nytimes.com/2021/04/30/technology/robot-surgery-surgeon.html\")\n",
    "my_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee3dc8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cleanText(text):\n",
    "#     text = re.sub(r'\\n|\\r', ' ', text)\n",
    "#     text = re.sub(r' +', ' ', text)\n",
    "#     text = text.strip()\n",
    "#     return text\n",
    "\n",
    "# doc = cleanText(my_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7f6efc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nest_sentences(document):\n",
    "    nested = []\n",
    "    sent = []\n",
    "    length = 0\n",
    "    for sentence in nltk.sent_tokenize(document):\n",
    "        length += len(sentence)\n",
    "        if length < 500:\n",
    "            sent.append(sentence)\n",
    "        else:\n",
    "            nested.append(sent)\n",
    "            sent = []\n",
    "            length = 0\n",
    "\n",
    "    if sent:\n",
    "        nested.append(sent)\n",
    "\n",
    "    return nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26f4962a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nested = nest_sentences(my_book)\n",
    "len(nested)\n",
    "# nested[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aaedf620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(BART_PATH, output_past=True)\n",
    "bart_tokenizer = BartTokenizer.from_pretrained(BART_PATH, output_past=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40060415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(nested_sentences):\n",
    "  device = 'cuda'\n",
    "  summaries = []\n",
    "  for nested in nested_sentences:\n",
    "    input_tokenized = bart_tokenizer.encode(' '.join(nested), truncation=True, return_tensors='pt')\n",
    "    input_tokenized = input_tokenized.to(device)\n",
    "    summary_ids = bart_model.to('cuda').generate(input_tokenized,\n",
    "                                      length_penalty=3.0,\n",
    "                                      min_length=30,\n",
    "                                      max_length=100)\n",
    "    output = [bart_tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "    summaries.append(output)\n",
    "  summaries = [sentence for sublist in summaries for sentence in sublist]\n",
    "  return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a6547568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "summ = generate_summary(nested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "baac9adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr. Danyal Fer wrapped his fingers around two metal handles near his chest. As he moved the handles, the robot mimicked each small motion with its own two arms.',\n",
       " 'Researchers at the University of California, Berkeley, showed how they hope to advance the state of the art. Dr. Fer let go of the handles, and a new kind of computer software took over.',\n",
       " 'The robot can match or even exceed a human in dexterity, precision and speed. The training exercise was originally designed for humans; moving the rings from peg to peg is how surgeons learn to operate robots.',\n",
       " 'Using many of the same technologies that underpin self-driving cars, autonomous drones and warehouse robots, researchers are working to automate surgical robots too. “It is an exciting time,” said Russell Taylor, a professor at Johns Hopkins University.',\n",
       " 'Robots can already exceed human accuracy on some surgical tasks. The hope is that automated robots can bring greater accuracy to other tasks, like incisions or suturing.',\n",
       " 'The car was driving on its own, he said, but his wife still had her hands on the wheel. “We can’t automate the whole process, at least not without human oversight,” he said.',\n",
       " 'Researchers implanted tiny markers in the pig’s intestines that emitted a near-infrared light. The method is far from practical, as the markers are not easily implanted or removed.',\n",
       " 'The change is driven by what are called neural networks, mathematical systems that can learn skills by analyzing vast amounts of data. By analyzing thousands of cat photos, for instance, a neural network can learn to recognize a cat. In much the same way, a Neural Network can learn from images captured by surgical robots.',\n",
       " 'The images provide a detailed road map showing how surgeries are performed. They can help new surgeons understand how to use these robots. By analyzing images that show how a surgeon guides the robot, a neural network can learn the same skills.',\n",
       " 'Dr. Fer and his colleagues collect images of the robot moving the plastic rings while under human control. Then their system learns from these images to pinpoint the best ways of grabbing the rings.',\n",
       " 'Human operators could compensate for this shift, unconsciously. But the automated system could not. This is often the problem with automated technology: It struggles to deal with change and uncertainty.',\n",
       " 'Once the automated system could account for this change, the robot could grab and move the plastics rings, matching the performance of human operators. Other labs are trying different approaches. Axel Krieger, a Johns Hopkins researcher, is working to automate a new kind of robotic arm.',\n",
       " '“It is like a car where the lane-following is autonomous but you still control the gas and the brake,” one researcher says. Many obstacles lie ahead, scientists note.',\n",
       " 'Doctors could perform surgery across distances far greater than the width of the operating room. The signal lag is too great to make that possible currently, Dr. Fer says.',\n",
       " '“When we start operating on people on the moon,” he said, “surgeons will need entirely new tools.”']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eefbb10",
   "metadata": {},
   "source": [
    "## using pretrained models/pipeline for auto-text summerization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "18de3c26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Dr. Danyal Fer wrapped his fingers around two metal handles near his chest.',\n",
       "  'As he moved the handles, the robot mimicked each small motion with its own two arms.',\n",
       "  'Researchers at the University of California, Berkeley, showed how they hope to advance the state of the art.',\n",
       "  'Dr. Fer let go of the handles, and a new kind of computer software took over.',\n",
       "  'The robot can match or even exceed a human in dexterity, precision and speed.'],\n",
       " ['Using many of the same technologies that underpin self-driving cars, autonomous drones and warehouse robots, researchers are working to automate surgical robots too.',\n",
       "  '“It is an exciting time,” said Russell Taylor, a professor at Johns Hopkins University.',\n",
       "  'Robots can already exceed human accuracy on some surgical tasks.',\n",
       "  'The hope is that automated robots can bring greater accuracy to other tasks, like incisions or suturing.'],\n",
       " ['“We can’t automate the whole process, at least not without human oversight,” he said.',\n",
       "  'Researchers implanted tiny markers in the pig’s intestines that emitted a near-infrared light.',\n",
       "  'The method is far from practical, as the markers are not easily implanted or removed.',\n",
       "  'The change is driven by what are called neural networks, mathematical systems that can learn skills by analyzing vast amounts of data.',\n",
       "  'By analyzing thousands of cat photos, for instance, a neural network can learn to recognize a cat.'],\n",
       " ['The images provide a detailed road map showing how surgeries are performed.',\n",
       "  'They can help new surgeons understand how to use these robots.',\n",
       "  'By analyzing images that show how a surgeon guides the robot, a neural network can learn the same skills.',\n",
       "  'Dr. Fer and his colleagues collect images of the robot moving the plastic rings while under human control.',\n",
       "  'Then their system learns from these images to pinpoint the best ways of grabbing the rings.'],\n",
       " ['But the automated system could not.',\n",
       "  'This is often the problem with automated technology: It struggles to deal with change and uncertainty.',\n",
       "  'Once the automated system could account for this change, the robot could grab and move the plastics rings, matching the performance of human operators.',\n",
       "  'Other labs are trying different approaches.',\n",
       "  'Axel Krieger, a Johns Hopkins researcher, is working to automate a new kind of robotic arm.'],\n",
       " ['Many obstacles lie ahead, scientists note.',\n",
       "  'Doctors could perform surgery across distances far greater than the width of the operating room.',\n",
       "  'The signal lag is too great to make that possible currently, Dr. Fer says.',\n",
       "  '“When we start operating on people on the moon,” he said, “surgeons will need entirely new tools.”']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_summ = nest_sentences(' '.join(summ))\n",
    "nested_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "afb883ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_output = generate_summary(nested_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c037b55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Researchers at the University of California, Berkeley, showed how they hope to advance the state of the art. The robot can match or even exceed a human in dexterity, precision and speed.',\n",
       " 'Researchers are working to automate surgical robots too. Robots can already exceed human accuracy on some surgical tasks. The hope is that automated robots can bring greater accuracy to other tasks.',\n",
       " 'Researchers implanted tiny markers in the pig’s intestines that emitted a near-infrared light. The method is far from practical, as the markers are not easily implanted or removed.',\n",
       " 'The images provide a detailed road map showing how surgeries are performed. They can help new surgeons understand how to use these robots. By analyzing images that show how a surgeon guides the robot, a neural network can learn the same skills.',\n",
       " 'The robot could grab and move the plastics rings, matching the performance of human operators. But the automated system could not deal with change and uncertainty. Other labs are trying different approaches.',\n",
       " 'Many obstacles lie ahead, scientists note. Doctors could perform surgery across distances far greater than the width of the operating room. “When we start operating on people on the moon,” he said, “surgeons will need entirely new tools”']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f83d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference source: https://www.britannica.com/topic/Around-the-World-in-Eighty-Days-by-Verne\n",
    "# Import refrence summary\n",
    "ref_file = openFile('ref.txt')\n",
    "\n",
    "#Clean refrence summary\n",
    "ref_summary = cleanText(ref_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c06b8446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert(string):\n",
    "    li = list(string.split(\".\"))\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b1bfed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Phileas Fogg, a London gentleman of meticulous and unchanging habits, hires as his valet Jean Passepartout, a Frenchman who has had a variety of jobs, including circus performer, but now seeks a tranquil life',\n",
       " ' After reading in The Daily Telegraph that a new railroad in India has made it theoretically possible to travel around the world in 80 days, Fogg bets his fellow members at the Reform Club that he will make that journey in 80 days or less; the wager is for the princely sum of Â£20,000 (half his fortune)',\n",
       " ' Leaving that night, Fogg and a nonplussed Passepartout board a train bound for Dover and Calais to begin their journey',\n",
       " ' Shortly before Foggâ€™s departure, someone resembling him had robbed a bank, and Foggâ€™s sudden exit leads Scotland Yard to believe that he was the bank robber',\n",
       " ' Accordingly, a detective, Mr',\n",
       " ' Fix, is sent to Suez, in British-ruled Egypt, to await the steamer Mongolia, on which Fogg and Passepartout are traveling',\n",
       " ' Fix befriends Passpartout, and, after learning that they will take the steamer to Bombay, he buys a ticket and joins them',\n",
       " ' The Mongolia reaches Bombay before the arrival of an arrest warrant, however',\n",
       " ' During the few hours before their planned departure for Calcutta on the Great India Peninsula Railway, Passepartout visits a Hindu temple on Malabar Hill, unaware that Christians are forbidden to enter and that shoes are not to be worn inside',\n",
       " ' He is beaten by enraged priests and barely makes it to the train station on time',\n",
       " ' The train travels through India until stopping at the village of Kholby, where Fogg learns that, contrary to what was reported in the British press, the railroad is 50 miles (81 km) short of completion, and passengers are required to find their own way to Allahabad to resume the train trip',\n",
       " ' Fogg purchases an elephant and hires a Parsi man as elephant driver and guide',\n",
       " ' The elephant-borne party later encounters a group of people preparing for an act of sutteeâ€”the immolation of a widow on her husbandâ€™s funeral pyre',\n",
       " ' Fogg decides that they must rescue the young widow',\n",
       " ' Passepartout disguises himself as the body of the late rajah, and, as soon as the pyre is lit, he springs up and seizes the widow',\n",
       " ' The party then flees before the ruse is discovered',\n",
       " ' They reach the railroad station in Allahabad and continue on their journey',\n",
       " '']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = Convert(ref_summary)\n",
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c64d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8eb09842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.10560533591410509,\n",
       "  'p': 0.08825891971057485,\n",
       "  'r': 0.15524981493748566},\n",
       " 'rouge-2': {'f': 0.004530396097373422,\n",
       "  'p': 0.004131064190382035,\n",
       "  'r': 0.005952380952380952},\n",
       " 'rouge-l': {'f': 0.09103945436289292,\n",
       "  'p': 0.076742861433437,\n",
       "  'r': 0.1305427567521709}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.get_scores(model_output, reference, avg=True, ignore_empty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e23c3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
